{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_dict(file_path, interval=30):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and extracts the list_time (timestamp), token_address, and pair_address for each token,\n",
    "    adjusting list_time to be 24 hours earlier and keeping end_time 30 minutes after the original list_time.\n",
    "    Removes entries where token_address is NaN.\n",
    "    Both list_time and end_time are formatted as ISO 8601 strings with a 'Z' suffix for UTC.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with token_address as keys and a nested dictionary containing\n",
    "              list_time (ISO 8601 string), end_time (ISO 8601 string), and pair_address as values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Initialize an empty dictionary\n",
    "    token_data = {}\n",
    "\n",
    "    # Loop through the DataFrame and populate the dictionary\n",
    "    for _, row in data.iterrows():\n",
    "        token_address = row['token_address']\n",
    "        \n",
    "        # Skip rows where token_address is NaN\n",
    "        if pd.isna(token_address):\n",
    "            continue\n",
    "\n",
    "        # Convert timestamp to datetime with UTC\n",
    "        original_list_time = pd.to_datetime(row['timestamp'], utc=True)\n",
    "        list_time = original_list_time# - timedelta(days=1)  # to make sure that the correct opening candle is found\n",
    "        end_time = original_list_time + timedelta(minutes=interval)  \n",
    "\n",
    "        # Format both times as ISO 8601 strings with 'Z' suffix\n",
    "        list_time_str = list_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        end_time_str = end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        \n",
    "        token_data[token_address] = {\n",
    "            'list_time': list_time_str,\n",
    "            'end_time': end_time_str,\n",
    "            'pair_address': row['pair_address']\n",
    "        }\n",
    "\n",
    "    return token_data\n",
    "\n",
    "\n",
    "def get_prices_bitquery(token_address, list_time, intervals=6, candle_size=5):\n",
    "\n",
    "#   # Construct the variables object\n",
    "#   variables = {\n",
    "#       \"token_address\": token_address,\n",
    "#       \"side_token\": \"So11111111111111111111111111111111111111112\",\n",
    "#       \"list_time\": list_time,\n",
    "#       \"intervals\": intervals,\n",
    "#       \"candle_size\": candle_size\n",
    "#   }\n",
    "\n",
    "    url = \"https://streaming.bitquery.io/eap\"\n",
    "    payload = json.dumps({\n",
    "    \"query\": \"query myQuery($token_address: String!, $side_token: String!, $list_time: DateTime, $intervals:Int, $candle_size:Int) {\\n      Solana(dataset: archive) {\\n        DEXTradeByTokens(\\n          orderBy: {ascendingByField: \\\"Block_Timefield\\\"}\\n          where: {\\n            Trade: {Currency: {MintAddress: {is: $token_address}}, Side: {Currency: {MintAddress: {is: $side_token}}}},\\n            Block: {Time: {since: $list_time}}\\n          }\\n          limit: {count: $intervals}\\n        ) {\\n          Block {\\n            Timefield: Time(interval: {in: minutes, count: $candle_size})\\n          }\\n          volume: sum(of: Trade_Amount)\\n          Trade {\\n            high: Price(maximum: Trade_Price)\\n            low: Price(minimum: Trade_Price)\\n            open: Price(minimum: Block_Slot)\\n            close: Price(maximum: Block_Slot)\\n          }\\n          count\\n        }\\n      }\\n    }\",\n",
    "    \"variables\": {  \n",
    "        \n",
    "        \"token_address\": token_address,\n",
    "        \"side_token\": \"So11111111111111111111111111111111111111112\",\n",
    "        \"list_time\": list_time,\n",
    "        \"intervals\": intervals,\n",
    "        \"candle_size\": candle_size}\n",
    "    })\n",
    "    headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer ory_at_FS-ZKnUvMPhhOZY6hcOcm_jiJ5o_HiFVUMQ7XudMUio.noVVWfojclJBJq0RTDs-Yw-TcDfM5lphLUFMU3rEb9A'\n",
    "    }\n",
    "\n",
    "\n",
    "  # Construct the payload\n",
    "#   payload = {\n",
    "#       \"query\": \"\"\"\n",
    "#           query myQuery($token_address: String!, $side_token: String!, $list_time: DateTime, $intervals:Int, $candle_size:Int) {\n",
    "#       Solana(dataset: archive) {\n",
    "#         DEXTradeByTokens(\n",
    "#           orderBy: {ascendingByField: \"Block_Timefield\"}\n",
    "#           where: {\n",
    "#             Trade: {Currency: {MintAddress: {is: $token_address}}, Side: {Currency: {MintAddress: {is: $side_token}}}},\n",
    "#             Block: {Time: {since: $list_time}}\n",
    "#           }\n",
    "#           limit: {count: $intervals}\n",
    "#         ) {\n",
    "#           Block {\n",
    "#             Timefield: Time(interval: {in: minutes, count: $candle_size})\n",
    "#           }\n",
    "#           volume: sum(of: Trade_Amount)\n",
    "#           Trade {\n",
    "#             high: Price(maximum: Trade_Price)\n",
    "#             low: Price(minimum: Trade_Price)\n",
    "#             open: Price(minimum: Block_Slot)\n",
    "#             close: Price(maximum: Block_Slot)\n",
    "#           }\n",
    "#           count\n",
    "#         }\n",
    "#       }\n",
    "#     }\n",
    "#     \"\"\",\n",
    "#       \"variables\": variables\n",
    "#   }\n",
    "\n",
    "    # Convert the payload to JSON\n",
    "    # payload_json = json.dumps(payload)\n",
    "\n",
    "    # url = \"https://streaming.bitquery.io/eap\"\n",
    "\n",
    "    # headers = {\n",
    "    #     'Content-Type': 'application/json',\n",
    "    #     'Authorization': 'Bearer ory_at_xy9nfzbBmtEG5AJ0Zj1VmSpADajEj_PWw7Ix6j5OBLg.wTpA3-_WBofQ6i3ssJwa2z8bB3glc7W7rs1fkjVCBYI'\n",
    "    # }\n",
    "\n",
    "    # Make the POST request\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "\n",
    "    # Parse the JSON response\n",
    "    try:\n",
    "        response = response.json()\n",
    "        return response[\"data\"][\"Solana\"][\"DEXTradeByTokens\"]\n",
    "    except (KeyError, json.JSONDecodeError) as e:\n",
    "        print(f\"Error parsing response: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# def process_token_data(token_data, intervals=6, candle_size=5):\n",
    "#     \"\"\"\n",
    "#     Processes the token_data dictionary by calling \n",
    "#      for each entry.\n",
    "\n",
    "#     Args:\n",
    "#         token_data (dict): The dictionary containing token information.\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary of responses for each token.\n",
    "#     \"\"\"\n",
    "#     results = {}\n",
    "#     count = 1\n",
    "#     for token_address, details in token_data.items():\n",
    "#         list_time = details['list_time']\n",
    "\n",
    "#         # Call the Bitquery API function\n",
    "#         print(f\"{count}. Fetching data for token: {token_address}\")\n",
    "#         response = get_prices_bitquery(token_address, list_time, intervals=intervals, candle_size=candle_size)\n",
    "\n",
    "#         # Store the result\n",
    "#         results[token_address] = response\n",
    "#         count += 1\n",
    "\n",
    "#     return results\n",
    "\n",
    "\n",
    "def fetch_and_store_prices_horizontal(token_data, intervals=6, candle_size=5):\n",
    "    \"\"\"\n",
    "    Fetches pricing data for all tokens in the token_data dictionary and stores it in a DataFrame\n",
    "    with candles stored horizontally.\n",
    "\n",
    "    Args:\n",
    "        token_data (dict): Dictionary containing token information.\n",
    "        intervals (int): Number of candles to fetch.\n",
    "        candle_size (int): Candle size in minutes.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the pricing data.\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to hold all data\n",
    "    all_data = []\n",
    "    token_count = 0\n",
    "\n",
    "    # Loop through the tokens in token_data\n",
    "    for token_address, details in token_data.items():\n",
    "        token_count += 1\n",
    "        list_time = details['list_time']\n",
    "\n",
    "        print(f\"{token_count}. Fetching data for token: {token_address}\")\n",
    "\n",
    "        # Fetch pricing data using get_prices_bitquery\n",
    "        response = get_prices_bitquery(\n",
    "            token_address=token_address,\n",
    "            list_time=list_time,\n",
    "            intervals=intervals,\n",
    "            candle_size=candle_size\n",
    "        )\n",
    "        \n",
    "        if not response:\n",
    "            print(f\"No data returned for token: {token_address}\")\n",
    "            if token_count % 25 == 0:\n",
    "                pd.DataFrame(all_data).to_csv(\"prices_partial_final.csv\", index=False)\n",
    "                print(f\"Partial data saved after processing {token_count} tokens.\")\n",
    "            continue\n",
    "\n",
    "        # Initialize a dictionary for this token\n",
    "        token_row = {\"Token Address\": token_address}\n",
    "\n",
    "        # Loop through the candles and structure them horizontally\n",
    "        for i, entry in enumerate(response):\n",
    "            candle_prefix = f\"Candle {i + 1}\"\n",
    "            token_row[f\"{candle_prefix}: Timefield\"] = entry['Block']['Timefield']\n",
    "            token_row[f\"{candle_prefix}: Open\"] = entry['Trade']['open']\n",
    "            token_row[f\"{candle_prefix}: High\"] = entry['Trade']['high']\n",
    "            token_row[f\"{candle_prefix}: Low\"] = entry['Trade']['low']\n",
    "            token_row[f\"{candle_prefix}: Close\"] = entry['Trade']['close']\n",
    "            token_row[f\"{candle_prefix}: Volume\"] = entry['volume']\n",
    "            token_row[f\"{candle_prefix}: Trades\"] = entry['count']\n",
    "\n",
    "        # Add the token row to the data\n",
    "        all_data.append(token_row)\n",
    "\n",
    "        if token_count % 25 == 0:\n",
    "            pd.DataFrame(all_data).to_csv(\"prices_partial_final.csv\", index=False)\n",
    "            print(f\"Partial data saved after processing {token_count} tokens.\")\n",
    "            \n",
    "        time.sleep(2)\n",
    "\n",
    "    # Convert all_data into a DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXAMPLE FROM BITQUERY\n",
    "\n",
    "# import requests\n",
    "# import json\n",
    "\n",
    "# token_address = \"8rkKQvCCyXTsxUpqsDvt3rj6X1E9NY2akMckowJXpump\"\n",
    "# list_time = \"2025-01-02T13:26:00Z\"\n",
    "# intervals = 6\n",
    "# candle_size = 5\n",
    "\n",
    "# url = \"https://streaming.bitquery.io/eap\"\n",
    "\n",
    "# payload = json.dumps({\n",
    "#    \"query\": \"query myQuery($token_address: String!, $side_token: String!, $list_time: DateTime, $intervals:Int, $candle_size:Int) {\\n      Solana(dataset: archive) {\\n        DEXTradeByTokens(\\n          orderBy: {ascendingByField: \\\"Block_Timefield\\\"}\\n          where: {\\n            Trade: {Currency: {MintAddress: {is: $token_address}}, Side: {Currency: {MintAddress: {is: $side_token}}}},\\n            Block: {Time: {since: $list_time}}\\n          }\\n          limit: {count: $intervals}\\n        ) {\\n          Block {\\n            Timefield: Time(interval: {in: minutes, count: $candle_size})\\n          }\\n          volume: sum(of: Trade_Amount)\\n          Trade {\\n            high: Price(maximum: Trade_Price)\\n            low: Price(minimum: Trade_Price)\\n            open: Price(minimum: Block_Slot)\\n            close: Price(maximum: Block_Slot)\\n          }\\n          count\\n        }\\n      }\\n    }\",\n",
    "#    \"variables\": {  \n",
    "      \n",
    "#       \"token_address\": token_address,\n",
    "#       \"side_token\": \"So11111111111111111111111111111111111111112\",\n",
    "#       \"list_time\": list_time,\n",
    "#       \"intervals\": intervals,\n",
    "#       \"candle_size\": candle_size}\n",
    "# })\n",
    "# headers = {\n",
    "#    'Content-Type': 'application/json',\n",
    "#    'Authorization': 'Bearer ory_at_FS-ZKnUvMPhhOZY6hcOcm_jiJ5o_HiFVUMQ7XudMUio.noVVWfojclJBJq0RTDs-Yw-TcDfM5lphLUFMU3rEb9A'\n",
    "# }\n",
    "\n",
    "# response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "# print(response.text)\n",
    "\n",
    "\n",
    "\n",
    "# file_path = 'migration_data_consol_17feb.csv'  # Replace with actual file path\n",
    "# token_data_dict = read_csv_to_dict(file_path, interval=30)  # Generate token data dictionary\n",
    "\n",
    "# # Extract the first key-value pair from the token_data dictionary\n",
    "# first_key, first_value = next(iter(token_data_dict.items()))\n",
    "\n",
    "# # Extract the details\n",
    "# token_address = first_key\n",
    "# list_time = first_value['list_time']\n",
    "\n",
    "# print(token_address)\n",
    "# print(list_time)\n",
    "\n",
    "# Call the Bitquery API for the first token\n",
    "# print(f\"Fetching data for token: {token_address}\")\n",
    "# response = get_prices_bitquery(token_address, list_time, intervals=2, candle_size=1)\n",
    "\n",
    "# file_path = 'migration_data_consol_17feb.csv'  # Replace with actual file path\n",
    "# token_data_dict = read_csv_to_dict(file_path, interval=30)  # Generate token data dictionary\n",
    "\n",
    "# # Extract the first entry from the token_data_dict\n",
    "# first_token_address, first_details = next(iter(token_data_dict.items()))\n",
    "\n",
    "# # Create a new dictionary with only the first entry\n",
    "# test_token_data = {first_token_address: first_details}\n",
    "\n",
    "# # Test the fetch_and_store_prices_horizontal function with just the first entry\n",
    "# df_test = fetch_and_store_prices_horizontal(test_token_data, intervals=6, candle_size=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Fetching data for token: 7hDga5yBae3pnzLZDddonwaCeriPneGUoR86n8Yzpump\n",
      "2. Fetching data for token: EMq4DCDP9mxHGn8ggXtgEgsySthqR7okT2ZfMPYYpump\n",
      "3. Fetching data for token: HrH1qcou1FEYfLJeZPLwbcVegzP4uAHQpc9yYxFDT1Sf\n",
      "4. Fetching data for token: DVdnbN1ad3ahV6s6rUCjzMCLzFev46qh8NLur6Ghpump\n",
      "5. Fetching data for token: 2zQQiJNTBAvhiV8Tj8JdLQ8FQmrgCDpoxQYB5q5Fpump\n",
      "6. Fetching data for token: E27z81okSxCViPTUPVgHa8wFW3FUfR51dBtK4vewpump\n",
      "7. Fetching data for token: BEhD6mgJc6DtsiYL4dJXSXgc9xcJzgqzdZV3AqLWpump\n",
      "8. Fetching data for token: Z5t4LmzuR3TjsrYqUxtQBma6zGwc1TjPsnTB5Hypump\n",
      "9. Fetching data for token: 2iT94v6igSWEGtEdwvw3b2vvroVAWHxg7YnNefRKpump\n",
      "10. Fetching data for token: 55ceg9igVr92sGWEARhc9Y6ira1tF5EBKwDCyYJgpump\n",
      "11. Fetching data for token: 6yP9wVigHY3b2awtTj2Ag9NU1bc9zYbS7qfoHbYgpump\n",
      "12. Fetching data for token: 5PTY9rNojz6RYT6j6GXVLFY6kb3SvFXKboNZcBQtpump\n",
      "13. Fetching data for token: Hu9FnqgvG8HacuUDrfRJvrttLsLyXVrWyHmnAXEJpump\n",
      "14. Fetching data for token: FpGmGZiZqsEVPuzos9yPLqPV6SGrRGr7GVWgVMsDpump\n",
      "15. Fetching data for token: 3naNzStYzJRBRsCrtcdMz8KN1eY26Jy5x1m3WdjTpump\n",
      "16. Fetching data for token: FUZp8E7bYguAxfdnMoPHjEgRhqbEC17EdpMrZ3T4pump\n",
      "17. Fetching data for token: FcEyqyH9BTMcDoHG4sWme88QTSZTTmJ12b4MBG5opump\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token Address</th>\n",
       "      <th>Candle 1: Timefield</th>\n",
       "      <th>Candle 1: Open</th>\n",
       "      <th>Candle 1: High</th>\n",
       "      <th>Candle 1: Low</th>\n",
       "      <th>Candle 1: Close</th>\n",
       "      <th>Candle 1: Volume</th>\n",
       "      <th>Candle 1: Trades</th>\n",
       "      <th>Candle 2: Timefield</th>\n",
       "      <th>Candle 2: Open</th>\n",
       "      <th>...</th>\n",
       "      <th>Candle 59: Close</th>\n",
       "      <th>Candle 59: Volume</th>\n",
       "      <th>Candle 59: Trades</th>\n",
       "      <th>Candle 60: Timefield</th>\n",
       "      <th>Candle 60: Open</th>\n",
       "      <th>Candle 60: High</th>\n",
       "      <th>Candle 60: Low</th>\n",
       "      <th>Candle 60: Close</th>\n",
       "      <th>Candle 60: Volume</th>\n",
       "      <th>Candle 60: Trades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7hDga5yBae3pnzLZDddonwaCeriPneGUoR86n8Yzpump</td>\n",
       "      <td>2025-02-17T07:49:00Z</td>\n",
       "      <td>2.691166e-03</td>\n",
       "      <td>2.826615e-03</td>\n",
       "      <td>2.658257e-03</td>\n",
       "      <td>2.825763e-03</td>\n",
       "      <td>1126119.524533</td>\n",
       "      <td>494</td>\n",
       "      <td>2025-02-17T07:50:00Z</td>\n",
       "      <td>2.811712e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.053206e-08</td>\n",
       "      <td>14422610.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-02-17T10:42:00Z</td>\n",
       "      <td>2.034345e-08</td>\n",
       "      <td>2.034345e-08</td>\n",
       "      <td>2.034345e-08</td>\n",
       "      <td>2.034345e-08</td>\n",
       "      <td>1108816.941031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMq4DCDP9mxHGn8ggXtgEgsySthqR7okT2ZfMPYYpump</td>\n",
       "      <td>2025-02-17T07:55:00Z</td>\n",
       "      <td>4.258742e-07</td>\n",
       "      <td>8.686355e-07</td>\n",
       "      <td>4.258742e-07</td>\n",
       "      <td>5.918547e-07</td>\n",
       "      <td>357170786.020096</td>\n",
       "      <td>300</td>\n",
       "      <td>2025-02-17T07:56:00Z</td>\n",
       "      <td>5.888564e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.930051e-08</td>\n",
       "      <td>18829.707941</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-17T12:49:00Z</td>\n",
       "      <td>1.929648e-08</td>\n",
       "      <td>1.929648e-08</td>\n",
       "      <td>1.929648e-08</td>\n",
       "      <td>1.929648e-08</td>\n",
       "      <td>178282.171315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HrH1qcou1FEYfLJeZPLwbcVegzP4uAHQpc9yYxFDT1Sf</td>\n",
       "      <td>2025-02-17T07:58:00Z</td>\n",
       "      <td>4.067587e-07</td>\n",
       "      <td>8.857043e-07</td>\n",
       "      <td>4.067587e-07</td>\n",
       "      <td>8.234595e-07</td>\n",
       "      <td>180999382.656279</td>\n",
       "      <td>252</td>\n",
       "      <td>2025-02-17T07:59:00Z</td>\n",
       "      <td>8.204029e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.792597e-06</td>\n",
       "      <td>41959444.477673</td>\n",
       "      <td>147</td>\n",
       "      <td>2025-02-17T08:57:00Z</td>\n",
       "      <td>1.802116e-06</td>\n",
       "      <td>2.122684e-06</td>\n",
       "      <td>1.802116e-06</td>\n",
       "      <td>2.073010e-06</td>\n",
       "      <td>31345342.443242</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DVdnbN1ad3ahV6s6rUCjzMCLzFev46qh8NLur6Ghpump</td>\n",
       "      <td>2025-02-17T07:59:00Z</td>\n",
       "      <td>3.973097e-07</td>\n",
       "      <td>8.996914e-07</td>\n",
       "      <td>3.541673e-07</td>\n",
       "      <td>6.780028e-07</td>\n",
       "      <td>1468768684.975825</td>\n",
       "      <td>1103</td>\n",
       "      <td>2025-02-17T08:00:00Z</td>\n",
       "      <td>6.744775e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.049031e-07</td>\n",
       "      <td>204881627.953060</td>\n",
       "      <td>245</td>\n",
       "      <td>2025-02-17T08:58:00Z</td>\n",
       "      <td>4.078722e-07</td>\n",
       "      <td>4.452360e-07</td>\n",
       "      <td>3.776885e-07</td>\n",
       "      <td>4.182268e-07</td>\n",
       "      <td>74672779.849515</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2zQQiJNTBAvhiV8Tj8JdLQ8FQmrgCDpoxQYB5q5Fpump</td>\n",
       "      <td>2025-02-17T08:07:00Z</td>\n",
       "      <td>1.995995e-07</td>\n",
       "      <td>2.406206e-07</td>\n",
       "      <td>1.982604e-07</td>\n",
       "      <td>2.406206e-07</td>\n",
       "      <td>52738535.830413</td>\n",
       "      <td>84</td>\n",
       "      <td>2025-02-17T08:08:00Z</td>\n",
       "      <td>2.484722e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.941674e-08</td>\n",
       "      <td>6424776.783376</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-17T09:39:00Z</td>\n",
       "      <td>1.927365e-08</td>\n",
       "      <td>1.927365e-08</td>\n",
       "      <td>1.927365e-08</td>\n",
       "      <td>1.927365e-08</td>\n",
       "      <td>468949.567133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Token Address   Candle 1: Timefield  \\\n",
       "0  7hDga5yBae3pnzLZDddonwaCeriPneGUoR86n8Yzpump  2025-02-17T07:49:00Z   \n",
       "1  EMq4DCDP9mxHGn8ggXtgEgsySthqR7okT2ZfMPYYpump  2025-02-17T07:55:00Z   \n",
       "2  HrH1qcou1FEYfLJeZPLwbcVegzP4uAHQpc9yYxFDT1Sf  2025-02-17T07:58:00Z   \n",
       "3  DVdnbN1ad3ahV6s6rUCjzMCLzFev46qh8NLur6Ghpump  2025-02-17T07:59:00Z   \n",
       "4  2zQQiJNTBAvhiV8Tj8JdLQ8FQmrgCDpoxQYB5q5Fpump  2025-02-17T08:07:00Z   \n",
       "\n",
       "   Candle 1: Open  Candle 1: High  Candle 1: Low  Candle 1: Close  \\\n",
       "0    2.691166e-03    2.826615e-03   2.658257e-03     2.825763e-03   \n",
       "1    4.258742e-07    8.686355e-07   4.258742e-07     5.918547e-07   \n",
       "2    4.067587e-07    8.857043e-07   4.067587e-07     8.234595e-07   \n",
       "3    3.973097e-07    8.996914e-07   3.541673e-07     6.780028e-07   \n",
       "4    1.995995e-07    2.406206e-07   1.982604e-07     2.406206e-07   \n",
       "\n",
       "    Candle 1: Volume Candle 1: Trades   Candle 2: Timefield  Candle 2: Open  \\\n",
       "0     1126119.524533              494  2025-02-17T07:50:00Z    2.811712e-03   \n",
       "1   357170786.020096              300  2025-02-17T07:56:00Z    5.888564e-07   \n",
       "2   180999382.656279              252  2025-02-17T07:59:00Z    8.204029e-07   \n",
       "3  1468768684.975825             1103  2025-02-17T08:00:00Z    6.744775e-07   \n",
       "4    52738535.830413               84  2025-02-17T08:08:00Z    2.484722e-07   \n",
       "\n",
       "   ...  Candle 59: Close  Candle 59: Volume  Candle 59: Trades  \\\n",
       "0  ...      2.053206e-08    14422610.000000                  2   \n",
       "1  ...      1.930051e-08       18829.707941                  1   \n",
       "2  ...      1.792597e-06    41959444.477673                147   \n",
       "3  ...      4.049031e-07   204881627.953060                245   \n",
       "4  ...      1.941674e-08     6424776.783376                  1   \n",
       "\n",
       "   Candle 60: Timefield Candle 60: Open Candle 60: High  Candle 60: Low  \\\n",
       "0  2025-02-17T10:42:00Z    2.034345e-08    2.034345e-08    2.034345e-08   \n",
       "1  2025-02-17T12:49:00Z    1.929648e-08    1.929648e-08    1.929648e-08   \n",
       "2  2025-02-17T08:57:00Z    1.802116e-06    2.122684e-06    1.802116e-06   \n",
       "3  2025-02-17T08:58:00Z    4.078722e-07    4.452360e-07    3.776885e-07   \n",
       "4  2025-02-17T09:39:00Z    1.927365e-08    1.927365e-08    1.927365e-08   \n",
       "\n",
       "   Candle 60: Close  Candle 60: Volume  Candle 60: Trades  \n",
       "0      2.034345e-08     1108816.941031                  1  \n",
       "1      1.929648e-08      178282.171315                  1  \n",
       "2      2.073010e-06    31345342.443242                203  \n",
       "3      4.182268e-07    74672779.849515                114  \n",
       "4      1.927365e-08      468949.567133                  1  \n",
       "\n",
       "[5 rows x 421 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interval_time = 60   # number of candles\n",
    "file_path = 'final tokens.csv'  \n",
    "token_data_dict = read_csv_to_dict(file_path, interval=interval_time) \n",
    "\n",
    "# Fetch and store prices\n",
    "df_prices_horizontal = fetch_and_store_prices_horizontal(token_data_dict, intervals=interval_time, candle_size=1)\n",
    "df_prices_horizontal.to_csv(\"prices_partial_final.csv\", index=False)\n",
    "df_prices_horizontal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
